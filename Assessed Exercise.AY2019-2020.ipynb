{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVMA (H) Image Transformations & Training Latent Spaces in Deep Convolutional Autoencoder Neural Networks\n",
    "### [your name] \n",
    "### [your matriculation number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> This exercise is my own work. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from bitstring import Bits, BitArray, BitStream\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io, scipy.ndimage, scipy.interpolate, scipy.signal\n",
    "import skimage.morphology, skimage.transform, skimage.feature\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (12.0, 6.0)\n",
    "\n",
    "#standard utilities\n",
    "def show_gray(img, title, **kwargs):\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap=\"gray\",  **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    \n",
    "def apply_color(img, fn):\n",
    "    return np.dstack((fn(img[:,:,0]),fn(img[:,:,1]),fn(img[:,:,2])))\n",
    "\n",
    "def load_and_normalise(fname):\n",
    "    return skimage.io.imread(fname) / 256.0\n",
    "\n",
    "### RGB/YIQ conversion code\n",
    "yiq_mat =  np.array([[ 0.30, 0.59, 0.114],[0.599, 0.2773, 0.3217],[0.213,0.5251,0.3121]])\n",
    "rgb_mat =  np.linalg.inv(yiq_mat)\n",
    "\n",
    "def rgb_to_yiq(rgb):\n",
    "    # RGB to YIQ\n",
    "    return np.dot(rgb, yiq_mat)    \n",
    "    \n",
    "def yiq_to_rgb(yiq):\n",
    "    # convert YIQ to RGB     \n",
    "    return np.clip(np.dot(yiq,rgb_mat),0,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;\n",
    "// this cell fixes the scroll boxes that are otherwise quite irritating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline DCNN code for classifying the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.leaky_relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    # description='PyTorch MNIST Example'\n",
    "    # --batch-size', type=int, default=64, metavar='N', help='input batch size for training (default: 64)\n",
    "    # --test-batch-size', type=int, default=1000, metavar='N', help='input batch size for testing (default: 1000)\n",
    "    # --epochs', type=int, default=10, metavar='N', help='number of epochs to train (default: 10)\n",
    "    # --lr', type=float, default=0.01, metavar='LR', help='learning rate (default: 0.01)\n",
    "    # --momentum', type=float, default=0.5, metavar='M', help='SGD momentum (default: 0.5)\n",
    "    # --no-cuda', action='store_true', default=False, help='disables CUDA training\n",
    "    # --seed', type=int, default=1, metavar='S', help='random seed (default: 1)\n",
    "    # --log-interval', type=int, default=10, metavar='N', help='how many batches to wait before logging training status\n",
    "    #\n",
    "    use_cuda = not False and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print('Hardware Processing Device:', device)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=64, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=1000, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    for epoch in range(1, 10 + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "[state the objectives of the lab clearly in your own words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach\n",
    "[explain how you approached the problem, any assumptions you made, any parts that you did not complete.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "[Put your code here, explaining it in markdown cells. ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "[Explain the experiments you performed. Include example plots of the loss and accuracy results for your best parameterisation of each network/filter set you develop.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "[Present your analysis and results. Include clear figures that explain your results. Do not include superfluous figures. ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "[briefly summarise what you have done. Discuss how well the baseline, optimsed, Gabor filter and your own filter networks perform, and how you might design and improved network based on using defined filter kernels.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
